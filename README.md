```markdown
# ğŸ§  Neural Network from Scratch (Pure Python Implementation)

A fully functional **neural network built from scratch in Python**, without relying on deep learning frameworks like TensorFlow or PyTorch.  
This project demonstrates the **core mechanics** behind neural networks â€” from forward propagation to backpropagation and gradient descent â€” with clean, modular, and well-documented code.

---

## ğŸš€ Features

âœ… **Custom Neural Network Class** â€“ Pure Python + NumPy implementation  
âœ… **Multiple Activation Functions** â€“ ReLU, Sigmoid, and Tanh  
âœ… **Configurable Architecture** â€“ Define any number of layers and neurons  
âœ… **Supports Both Tasks** â€“ Classification & Regression  
âœ… **Mini-Batch Gradient Descent** â€“ Efficient training  
âœ… **Real-Time Training Visualization** â€“ Loss and accuracy plots  
âœ… **Comprehensive Evaluation Metrics** â€“ Accuracy, MSE, and RÂ² score  

---

## ğŸ§© Project Structure

```
neural_network_demo/
â”œâ”€â”€ neural_network.py      # Core neural network implementation (classification)
â”œâ”€â”€ main.py                # Demo for classification and regression
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ run.bat                # Run script for Windows
â”œâ”€â”€ run.sh                 # Run script for Linux/Mac
â”œâ”€â”€ README.md              # Project documentation
â””â”€â”€ .gitignore             # Ignore unnecessary files
```

---

## âš™ï¸ Installation

1ï¸âƒ£ Clone the repository:
```bash
git clone https://github.com/sankhya007/neural_network_demo.git
cd neural_network_demo
```

2ï¸âƒ£ Install dependencies:
```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Usage

Run the demo:
```bash
python main.py
```

Youâ€™ll see:
- Training progress with live updates every 100 epochs  
- Real-time loss and accuracy visualization  
- Final evaluation metrics for both classification and regression tasks  

---

## ğŸ“Š Results

- Achieves **~78% accuracy** on multi-class classification datasets  
- Smooth convergence curves for both **loss** and **accuracy**
- Regression model yields strong **RÂ² performance** and low **MSE**  

---

## ğŸ§  Concepts Covered

- Forward Propagation  
- Backpropagation  
- Activation Functions (ReLU, Sigmoid, Tanh)  
- Softmax Output for Multi-Class Problems  
- Mini-Batch Gradient Descent  
- Loss Functions (Cross-Entropy & MSE)  
- Model Evaluation Metrics  

---

## ğŸ“ˆ Example Visualizations

- **Classification:** Loss & Accuracy curves over epochs  
- **Regression:** Predicted vs Actual scatter plot with RÂ² score  
- **Training Diagnostics:** Validation loss tracking

---

## ğŸ’¡ Future Improvements

- Add dropout and batch normalization  
- Implement momentum and Adam optimizers  
- Save and load trained model weights  
- Extend to support convolutional layers

---

## ğŸ§‘â€ğŸ’» Author

**Sankhyapriyo Dey**  
ğŸ“§ [GitHub Profile](https://github.com/sankhya007)  

---

## ğŸªª License

This project is released under the **MIT License** â€“ free to use and modify.

---
```